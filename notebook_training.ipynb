{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "stone-asbestos",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "\n",
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from misc import *\n",
    "import tensorflow as tf\n",
    "import os \n",
    "from RNN_models import *\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "path = \"/home/cooper-cooper/continous/\"\n",
    "itraj = 0\n",
    "epochs = 20\n",
    "\n",
    "means = np.load(path+\"{}/means.npy\".format(itraj), allow_pickle=True).astype(np.float32) ### this is \\textbf{q}(t)\n",
    "covs = np.load(path+\"{}/covs.npy\".format(itraj), allow_pickle=True).astype(np.float32) ## this is the \\Sigma(t)\n",
    "xicovs = np.load(path+\"{}/xicovs.npy\".format(itraj), allow_pickle=True).astype(np.float32) ## this is the \\Chi(\\Sigma) (evolution)\n",
    "signals = np.load(path+\"{}/signals.npy\".format(itraj), allow_pickle=True).astype(np.float32) ##this is the dy's\n",
    "A = np.load(path+\"{}/A.npy\".format(itraj), allow_pickle=True).astype(np.float32)\n",
    "dt = np.load(path+\"{}/dt.npy\".format(itraj), allow_pickle=True)[0]\n",
    "C = np.load(path+\"{}/C.npy\".format(itraj), allow_pickle=True).astype(np.float32)\n",
    "D = np.load(path+\"{}/D.npy\".format(itraj), allow_pickle=True).astype(np.float32)\n",
    "\n",
    "coeffs = [C, A, D , dt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "pleasant-indianapolis",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  10,  231,  452,  673,  894, 1115, 1336, 1557, 1778, 1999])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linspace(10,len(signals),10).astype(np.int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "driving-system",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['gaussian_recu_model_11/rnn_11/stacked_rnn_cells_11/gaussian_dynamics__recurrent_cell_11/kernel:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['gaussian_recu_model_11/rnn_11/stacked_rnn_cells_11/gaussian_dynamics__recurrent_cell_11/kernel:0'] when minimizing the loss.\n",
      "1/1 [==============================] - 0s 1ms/step - total_loss: 0.0181 - Coeffs_A: -0.0152\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 815us/step - total_loss: 0.0180 - Coeffs_A: -0.0202\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 875us/step - total_loss: 0.0180 - Coeffs_A: -0.0251\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 819us/step - total_loss: 0.0179 - Coeffs_A: -0.0301\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 1ms/step - total_loss: 0.0179 - Coeffs_A: -0.0350\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 813us/step - total_loss: 0.0179 - Coeffs_A: -0.0399\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 805us/step - total_loss: 0.0178 - Coeffs_A: -0.0447\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 889us/step - total_loss: 0.0178 - Coeffs_A: -0.0496\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 1ms/step - total_loss: 0.0178 - Coeffs_A: -0.0543\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 822us/step - total_loss: 0.0177 - Coeffs_A: -0.0590\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 813us/step - total_loss: 0.0177 - Coeffs_A: -0.0637\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 963us/step - total_loss: 0.0177 - Coeffs_A: -0.0683\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 798us/step - total_loss: 0.0177 - Coeffs_A: -0.0728\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 860us/step - total_loss: 0.0176 - Coeffs_A: -0.0772\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 1ms/step - total_loss: 0.0176 - Coeffs_A: -0.0815\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 813us/step - total_loss: 0.0176 - Coeffs_A: -0.0858\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 871us/step - total_loss: 0.0176 - Coeffs_A: -0.0899\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 820us/step - total_loss: 0.0175 - Coeffs_A: -0.0939\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 917us/step - total_loss: 0.0175 - Coeffs_A: -0.0978\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 2ms/step - total_loss: 0.0175 - Coeffs_A: -0.1016\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 906us/step - total_loss: 0.0175 - Coeffs_A: -0.1052\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 867us/step - total_loss: 0.0174 - Coeffs_A: -0.1087\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 1ms/step - total_loss: 0.0174 - Coeffs_A: -0.1121\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 951us/step - total_loss: 0.0174 - Coeffs_A: -0.1153\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 1ms/step - total_loss: 0.0174 - Coeffs_A: -0.1183\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 821us/step - total_loss: 0.0174 - Coeffs_A: -0.1212\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 814us/step - total_loss: 0.0173 - Coeffs_A: -0.1239\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 1ms/step - total_loss: 0.0173 - Coeffs_A: -0.1264\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 812us/step - total_loss: 0.0173 - Coeffs_A: -0.1288\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 986us/step - total_loss: 0.0173 - Coeffs_A: -0.1310\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 1ms/step - total_loss: 0.0173 - Coeffs_A: -0.1330\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 873us/step - total_loss: 0.0172 - Coeffs_A: -0.1349\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 1ms/step - total_loss: 0.0172 - Coeffs_A: -0.1366\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 2ms/step - total_loss: 0.0172 - Coeffs_A: -0.1380\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 1ms/step - total_loss: 0.0172 - Coeffs_A: -0.1394\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 1ms/step - total_loss: 0.0172 - Coeffs_A: -0.1405\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 2ms/step - total_loss: 0.0172 - Coeffs_A: -0.1415\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 2ms/step - total_loss: 0.0172 - Coeffs_A: -0.1423\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 1ms/step - total_loss: 0.0171 - Coeffs_A: -0.1429\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 1ms/step - total_loss: 0.0171 - Coeffs_A: -0.1433\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 1ms/step - total_loss: 0.0171 - Coeffs_A: -0.1436\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 2ms/step - total_loss: 0.0171 - Coeffs_A: -0.1438\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 2ms/step - total_loss: 0.0171 - Coeffs_A: -0.1438\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 1ms/step - total_loss: 0.0171 - Coeffs_A: -0.1436\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 1ms/step - total_loss: 0.0171 - Coeffs_A: -0.1433\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 1ms/step - total_loss: 0.0170 - Coeffs_A: -0.1429\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 2ms/step - total_loss: 0.0170 - Coeffs_A: -0.1424\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 1ms/step - total_loss: 0.0170 - Coeffs_A: -0.1417\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 1ms/step - total_loss: 0.0170 - Coeffs_A: -0.1409\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 1ms/step - total_loss: 0.0170 - Coeffs_A: -0.1400\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 1ms/step - total_loss: 0.0170 - Coeffs_A: -0.1390\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 1ms/step - total_loss: 0.0170 - Coeffs_A: -0.1379\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 1ms/step - total_loss: 0.0169 - Coeffs_A: -0.1367\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 1ms/step - total_loss: 0.0169 - Coeffs_A: -0.1355\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 1ms/step - total_loss: 0.0169 - Coeffs_A: -0.1342\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 1ms/step - total_loss: 0.0169 - Coeffs_A: -0.1327\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 2ms/step - total_loss: 0.0169 - Coeffs_A: -0.1313\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 1ms/step - total_loss: 0.0169 - Coeffs_A: -0.1298\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 1ms/step - total_loss: 0.0169 - Coeffs_A: -0.1282\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 6ms/step - total_loss: 0.0169 - Coeffs_A: -0.1266\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 1ms/step - total_loss: 0.0169 - Coeffs_A: -0.1249\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 2ms/step - total_loss: 0.0168 - Coeffs_A: -0.1233\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 1ms/step - total_loss: 0.0168 - Coeffs_A: -0.1216\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 1ms/step - total_loss: 0.0168 - Coeffs_A: -0.1198\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 2ms/step - total_loss: 0.0168 - Coeffs_A: -0.1181\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 1ms/step - total_loss: 0.0168 - Coeffs_A: -0.1164\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 2ms/step - total_loss: 0.0168 - Coeffs_A: -0.1146\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 1ms/step - total_loss: 0.0168 - Coeffs_A: -0.1129\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 1ms/step - total_loss: 0.0168 - Coeffs_A: -0.1111\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 2ms/step - total_loss: 0.0168 - Coeffs_A: -0.1094\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 1ms/step - total_loss: 0.0168 - Coeffs_A: -0.1077\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 2ms/step - total_loss: 0.0167 - Coeffs_A: -0.1060\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 1ms/step - total_loss: 0.0167 - Coeffs_A: -0.1043\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 1ms/step - total_loss: 0.0167 - Coeffs_A: -0.1027\n",
      "Epoch 75/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 1ms/step - total_loss: 0.0167 - Coeffs_A: -0.1010\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 2ms/step - total_loss: 0.0167 - Coeffs_A: -0.0995\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 1ms/step - total_loss: 0.0167 - Coeffs_A: -0.0979\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 1ms/step - total_loss: 0.0167 - Coeffs_A: -0.0964\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 1ms/step - total_loss: 0.0167 - Coeffs_A: -0.0949\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 1ms/step - total_loss: 0.0167 - Coeffs_A: -0.0935\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 1ms/step - total_loss: 0.0167 - Coeffs_A: -0.0921\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 1ms/step - total_loss: 0.0167 - Coeffs_A: -0.0907\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 1ms/step - total_loss: 0.0167 - Coeffs_A: -0.0894\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 1ms/step - total_loss: 0.0166 - Coeffs_A: -0.0881\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 1ms/step - total_loss: 0.0166 - Coeffs_A: -0.0869\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 2ms/step - total_loss: 0.0166 - Coeffs_A: -0.0857\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 1ms/step - total_loss: 0.0166 - Coeffs_A: -0.0846\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 1ms/step - total_loss: 0.0166 - Coeffs_A: -0.0835\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 1ms/step - total_loss: 0.0166 - Coeffs_A: -0.0825\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 1ms/step - total_loss: 0.0166 - Coeffs_A: -0.0815\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 1ms/step - total_loss: 0.0166 - Coeffs_A: -0.0805\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 2ms/step - total_loss: 0.0166 - Coeffs_A: -0.0796\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 2ms/step - total_loss: 0.0166 - Coeffs_A: -0.0788\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 1ms/step - total_loss: 0.0166 - Coeffs_A: -0.0780\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 1ms/step - total_loss: 0.0166 - Coeffs_A: -0.0772\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 1ms/step - total_loss: 0.0166 - Coeffs_A: -0.0765\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 1ms/step - total_loss: 0.0166 - Coeffs_A: -0.0758\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 1ms/step - total_loss: 0.0166 - Coeffs_A: -0.0751\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 1ms/step - total_loss: 0.0166 - Coeffs_A: -0.0745\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 1ms/step - total_loss: 0.0166 - Coeffs_A: -0.0739\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = GaussianRecuModel(coeffs)\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(lr=0.01))\n",
    "model(sliced_dataset(signals, xicovs,1))\n",
    "initial_A = model.trainable_variables\n",
    "\n",
    "\n",
    "### training ####\n",
    "history_A, history_loss = [], []\n",
    "for time_slice in [-1]:#tqdm(np.linspace(10,len(signals),10).astype(np.int)):\n",
    "    inputs = sliced_dataset(signals, xicovs,time_slice)\n",
    "    histo = model.fit(x=inputs, y=inputs[1][tf.newaxis,:,:], epochs=100, verbose=1)\n",
    "    for k,v in zip(histo.history[\"Coeffs_A\"], histo.history[\"total_loss\"]):\n",
    "        history_A.append(k)\n",
    "        history_loss.append(v)\n",
    "\n",
    "\n",
    "#os.makedirs(\"/data/uab-giq/scratch/matias/quantera/trajectories/{}/\".format(itraj), exist_ok=True)\n",
    "np.save(path+\"{}/A_history\".format(itraj),np.array(history_A) )\n",
    "np.save(path+\"{}/loss_history\".format(itraj),np.array(history_loss) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "adapted-democracy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.18201381,  1.0389047 ],\n",
       "       [-1.116195  , -0.02561519]], dtype=float32)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history_A[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "complimentary-blake",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
